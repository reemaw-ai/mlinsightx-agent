{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6849,"sourceType":"datasetVersion","datasetId":4471},{"sourceId":13911348,"sourceType":"datasetVersion","datasetId":8863951},{"sourceId":11675860,"sourceType":"kernelVersion"},{"sourceId":11793463,"sourceType":"kernelVersion"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Import Libraries\n**Purpose:** Import all the required libraries for ML modeling, explainability, visualization, and Google ADK/ Gemini integration.","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport logging\nfrom typing import Dict, Any, List\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\nfrom sklearn.inspection import permutation_importance, PartialDependenceDisplay\nfrom lightgbm import LGBMClassifier\nimport shap\n# Gemini\nfrom google import genai\nfrom google.genai import types as genai_types\n# ADK core\nfrom google.adk.agents import LlmAgent\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.models import LlmRequest\nfrom google.adk.a2a.utils.agent_to_a2a import to_a2a\nprint(\"Imports complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:59:36.130623Z","iopub.execute_input":"2025-11-30T14:59:36.131545Z","iopub.status.idle":"2025-11-30T14:59:36.144898Z","shell.execute_reply.started":"2025-11-30T14:59:36.131511Z","shell.execute_reply":"2025-11-30T14:59:36.143725Z"}},"outputs":[{"name":"stdout","text":"Imports complete.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Configuration and Authentication\n**Purpose:** Set up logging, authenticate with Google API, initialize Gemini client, and create global memory storage.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\nlogging.basicConfig(\n   level=logging.INFO,\n   format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n)\nlogger = logging.getLogger(\"mlinsightx\")\n#Gemini Config\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"âœ… Setup and authentication complete.\")\nexcept Exception as e:\n    print(\n        f\"ðŸ”‘ Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )\n\nGEMINI_MODEL = \"gemini-2.0-flash-exp\" \nif GOOGLE_API_KEY:\n   genai_client = genai.Client(api_key=GOOGLE_API_KEY)\n   logger.info(\"Gemini client initialized with model %s\", GEMINI_MODEL)\nelse:\n   genai_client = None\n   logger.warning(\"No GOOGLE_API_KEY found. Using fallback text only.\")\n\nartifacts: Dict[str, Any] = {}\nprint(\"Config + logging ready; MemoryBank initialized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:59:44.250194Z","iopub.execute_input":"2025-11-30T14:59:44.250566Z","iopub.status.idle":"2025-11-30T14:59:44.625533Z","shell.execute_reply.started":"2025-11-30T14:59:44.250541Z","shell.execute_reply":"2025-11-30T14:59:44.624330Z"}},"outputs":[{"name":"stdout","text":"âœ… Setup and authentication complete.\nConfig + logging ready; MemoryBank initialized.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Load Dataset\n**Purpose:** Load the Bank Marketing dataset from Kaggle input directory.","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\ndef load_bank_marketing() -> pd.DataFrame:\n   logger.info(\"Loading Bank Marketing dataset from local files...\")\n   possible_paths =  [\n        \"/kaggle/input/bank-csv/bank.csv\",\n    ]\n   for p in possible_paths:\n       if Path(p).exists():\n           logger.info(\"Found dataset at: %s\", p)\n           df = pd.read_csv(p)\n          # df = pd.read_csv(p, sep=\";\")\n           print (\"Using dataset:\", p)\n           return df\n   raise FileNotFoundError(\n       \"bank.csv not found. Please attach a Bank Marketing dataset to this Kaggle notebook.\"\n   )\ndf = load_bank_marketing()\n\nprint(df.head())\nprint(\"Shape:\", df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T14:59:58.084699Z","iopub.execute_input":"2025-11-30T14:59:58.085084Z","iopub.status.idle":"2025-11-30T14:59:58.128011Z","shell.execute_reply.started":"2025-11-30T14:59:58.085057Z","shell.execute_reply":"2025-11-30T14:59:58.126989Z"}},"outputs":[{"name":"stdout","text":"Using dataset: /kaggle/input/bank-csv/bank.csv\n   age          job  marital  education default  balance housing loan  \\\n0   30   unemployed  married    primary      no     1787      no   no   \n1   33     services  married  secondary      no     4789     yes  yes   \n2   35   management   single   tertiary      no     1350     yes   no   \n3   30   management  married   tertiary      no     1476     yes  yes   \n4   59  blue-collar  married  secondary      no        0     yes   no   \n\n    contact  day month  duration  campaign  pdays  previous poutcome   y  \n0  cellular   19   oct        79         1     -1         0  unknown  no  \n1  cellular   11   may       220         1    339         4  failure  no  \n2  cellular   16   apr       185         1    330         1  failure  no  \n3   unknown    3   jun       199         4     -1         0  unknown  no  \n4   unknown    5   may       226         1     -1         0  unknown  no  \nShape: (4521, 17)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Data Preprocessing & Model Training\n**Purpose:** Prepare data, build ML pipeline with preprocessing, train LightGBM classifier, and evaluate performance. ","metadata":{}},{"cell_type":"code","source":"TARGET_COL = \"y\"\nassert TARGET_COL in df.columns, f\"Target column '{TARGET_COL}' not found.\"\n\ny = (df[TARGET_COL].astype(str).str.lower().isin([\"yes\", \"1\", \"true\", \"success\"])).astype(int)\nX = df.drop(columns=[TARGET_COL])\nnumeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\ncategorical_features = X.select_dtypes(exclude=[\"int64\", \"float64\"]).columns.tolist()\nlogger.info(\"Numeric features: %s\", numeric_features)\nlogger.info(\"Categorical features: %s\", categorical_features)\nX_train, X_test, y_train, y_test = train_test_split(\n   X, y, test_size=0.2, random_state=42, stratify=y\n)\nnumeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\ncategorical_transformer = Pipeline(\n   steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]\n)\npreprocessor = ColumnTransformer(\n   transformers=[\n       (\"num\", numeric_transformer, numeric_features),\n       (\"cat\", categorical_transformer, categorical_features),\n   ]\n)\nlgbm = LGBMClassifier(\n   random_state=42,\n   n_estimators=200,\n   learning_rate=0.05,\n   max_depth=-1,\n)\npipeline = Pipeline(\n   steps=[\n       (\"preprocessor\", preprocessor),\n       (\"model\", lgbm),\n   ]\n)\nlogger.info(\"Training LightGBM pipeline...\")\npipeline.fit(X_train, y_train)\ny_pred = pipeline.predict(X_test)\ny_proba = pipeline.predict_proba(X_test)[:, 1]\nmetrics = {\n   \"accuracy\": float(accuracy_score(y_test, y_pred)),\n   \"f1\": float(f1_score(y_test, y_pred)),\n   \"roc_auc\": float(roc_auc_score(y_test, y_proba)),\n}\nlogger.info(\"Metrics: %s\", metrics)\n\nartifacts[\"pipeline\"] = pipeline\nartifacts[\"X_train\"] = X_train\nartifacts[\"X_test\"] = X_test\nartifacts[\"y_train\"] = y_train\nartifacts[\"y_test\"] = y_test\nartifacts[\"metrics\"] = metrics\nartifacts[\"numeric_features\"] = numeric_features\nartifacts[\"categorical_features\"] = categorical_features\nprint(\"Training complete. Metrics:\", metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:00:01.492643Z","iopub.execute_input":"2025-11-30T15:00:01.493657Z","iopub.status.idle":"2025-11-30T15:00:01.899816Z","shell.execute_reply.started":"2025-11-30T15:00:01.493620Z","shell.execute_reply":"2025-11-30T15:00:01.898453Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 417, number of negative: 3199\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000676 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 953\n[LightGBM] [Info] Number of data points in the train set: 3616, number of used features: 50\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115321 -> initscore=-2.037507\n[LightGBM] [Info] Start training from score -2.037507\nTraining complete. Metrics: {'accuracy': 0.8950276243093923, 'f1': 0.46327683615819215, 'roc_auc': 0.9093560933448573}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Explainability Functions\n**Purpose:** Define functions for computing SHAP values, permutation importance, and partial dependence plots.","metadata":{}},{"cell_type":"code","source":"def compute_shap_values(\n   pipeline: Pipeline,\n   X_background: pd.DataFrame,\n   X_sample: pd.DataFrame\n):\n   \"\"\"\n   Computes SHAP values using LightGBM's TreeExplainer.\n   \"\"\"\n   logger.info(\"Computing SHAP values (TreeExplainer, LightGBM)...\")\n   model = pipeline.named_steps[\"model\"]\n   preprocessor = pipeline.named_steps[\"preprocessor\"]\n   # Transform background & sample using the pipeline's preprocessor\n   X_bg_trans = preprocessor.transform(X_background)\n   X_sample_trans = preprocessor.transform(X_sample)\n   # Feature names after transformation\n   feature_names = preprocessor.get_feature_names_out()\n   # TreeExplainer works directly on model inputs\n   explainer = shap.TreeExplainer(model)\n   shap_values = explainer.shap_values(X_sample_trans)\n   logger.info(\"SHAP calculation done. Shape: %s\", np.array(shap_values).shape)\n   return {\n       \"shap_values\": shap_values,\n       \"expected_value\": explainer.expected_value,\n       \"feature_names\": list(feature_names),\n   }\n\ndef compute_permutation_importance(\n   pipeline: Pipeline,\n   X_test: pd.DataFrame,\n   y_test: pd.Series\n):\n   \"\"\"\n   Computes permutation importance using transformed input.\n   \"\"\"\n   logger.info(\"Computing permutation importance...\")\n   preprocessor = pipeline.named_steps[\"preprocessor\"]\n   model = pipeline.named_steps[\"model\"]\n   # Transform before permutation importance\n   X_test_trans = preprocessor.transform(X_test)\n   feature_names = preprocessor.get_feature_names_out()\n   result = permutation_importance(\n       model,\n       X_test_trans,\n       y_test,\n       n_repeats=10,\n       random_state=42,\n       n_jobs=-1,\n   )\n   logger.info(\"Permutation importance done.\")\n   return {\n       \"importances_mean\": result.importances_mean.tolist(),\n       \"importances_std\": result.importances_std.tolist(),\n       \"feature_names\": list(feature_names),\n   }\n\ndef compute_pdp(\n   pipeline: Pipeline,\n   X: pd.DataFrame,\n   features: List[str],\n   output_dir: str = \"pdp_plots\",\n):\n   \"\"\"\n   Computes PDP for transformed features.\n   \"\"\"\n   logger.info(\"Computing PDP for features: %s\", features)\n   os.makedirs(output_dir, exist_ok=True)\n   preprocessor = pipeline.named_steps[\"preprocessor\"]\n   model = pipeline.named_steps[\"model\"]\n   # Transform X\n   X_trans = preprocessor.transform(X)\n   feature_names = list(preprocessor.get_feature_names_out())\n   saved_paths = []\n   # Map categorical names to feature indices\n   name_to_index = {name: idx for idx, name in enumerate(feature_names)}\n   for feat in features:\n\n       matching_features = [\n           name for name in feature_names if name.startswith(feat + \"_\") or name == feat\n       ]\n       if not matching_features:\n           logger.warning(\"Feature %s not found in transformed feature set.\", feat)\n           continue\n       for mf in matching_features:\n           idx = name_to_index[mf]\n           fig, ax = plt.subplots()\n           try:\n               PartialDependenceDisplay.from_estimator(\n                   model,\n                   X_trans,\n                   [idx],\n                   kind=\"average\",\n                   ax=ax,\n                   grid_resolution=50\n               )\n               ax.set_title(f\"PDP - {mf}\")\n               path = os.path.join(output_dir, f\"pdp_{mf}.png\")\n               fig.savefig(path, bbox_inches=\"tight\")\n               plt.close(fig)\n               saved_paths.append(path)\n           except Exception as e:\n               logger.warning(f\"PDP failed for {mf}: {e}\")\n               plt.close(fig)\n               continue\n   logger.info(\"PDP generation done. Saved %d plots.\", len(saved_paths))\n   return saved_paths\n\nprint(\"Explainability functions redefined (SHAP, Perm, PDP).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:00:10.001745Z","iopub.execute_input":"2025-11-30T15:00:10.002067Z","iopub.status.idle":"2025-11-30T15:00:10.019573Z","shell.execute_reply.started":"2025-11-30T15:00:10.002045Z","shell.execute_reply":"2025-11-30T15:00:10.018473Z"}},"outputs":[{"name":"stdout","text":"Explainability functions redefined (SHAP, Perm, PDP).\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Execute Explainability Analysis\n**Purpose**: Run all explainability tools and create a global explanation summary.","metadata":{}},{"cell_type":"code","source":"logger.info(\"Running explainability tools...\")\npipeline = artifacts[\"pipeline\"]\nX_train = artifacts[\"X_train\"]\nX_test = artifacts[\"X_test\"]\ny_test = artifacts[\"y_test\"]\n# 1. Prepare SHAP background \nX_background = X_train.sample(n=min(200, len(X_train)), random_state=42)\nX_sample = X_test.sample(n=min(200, len(X_test)), random_state=42)\n# 2. Run SHAP\nshap_result = compute_shap_values(\n   pipeline=pipeline,\n   X_background=X_background,\n   X_sample=X_sample\n)\n# 3. Run Permutation Importance\nperm_result = compute_permutation_importance(\n   pipeline=pipeline,\n   X_test=X_test,\n   y_test=y_test\n)\n# 4. Run PDP for top features \nfeature_names = shap_result[\"feature_names\"]\npdp_paths = compute_pdp(\n   pipeline=pipeline,\n   X=X_test,\n   features=list(set([fn.split(\"_\")[0] for fn in feature_names])), \n   output_dir=\"pdp_plots\"\n)\n# 5. Store results\nartifacts[\"shap_result\"] = shap_result\nartifacts[\"perm_result\"] = perm_result\nartifacts[\"pdp_paths\"] = pdp_paths\nprint(\"Explainability completed.\")\nprint(\"SHAP values shape:\", np.array(shap_result[\"shap_values\"]).shape)\nprint(\"Permutation features:\", perm_result[\"feature_names\"])\nprint(\"Saved PDP plots:\", len(pdp_paths))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:00:18.428492Z","iopub.execute_input":"2025-11-30T15:00:18.428852Z","iopub.status.idle":"2025-11-30T15:00:45.467676Z","shell.execute_reply.started":"2025-11-30T15:00:18.428826Z","shell.execute_reply":"2025-11-30T15:00:45.466704Z"}},"outputs":[{"name":"stderr","text":"LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\nAttempting to set identical low and high ylims makes transformation singular; automatically expanding.\nAttempting to set identical low and high ylims makes transformation singular; automatically expanding.\nAttempting to set identical low and high ylims makes transformation singular; automatically expanding.\n","output_type":"stream"},{"name":"stdout","text":"Explainability completed.\nSHAP values shape: (2, 200, 51)\nPermutation features: ['num__age', 'num__balance', 'num__day', 'num__duration', 'num__campaign', 'num__pdays', 'num__previous', 'cat__job_admin.', 'cat__job_blue-collar', 'cat__job_entrepreneur', 'cat__job_housemaid', 'cat__job_management', 'cat__job_retired', 'cat__job_self-employed', 'cat__job_services', 'cat__job_student', 'cat__job_technician', 'cat__job_unemployed', 'cat__job_unknown', 'cat__marital_divorced', 'cat__marital_married', 'cat__marital_single', 'cat__education_primary', 'cat__education_secondary', 'cat__education_tertiary', 'cat__education_unknown', 'cat__default_no', 'cat__default_yes', 'cat__housing_no', 'cat__housing_yes', 'cat__loan_no', 'cat__loan_yes', 'cat__contact_cellular', 'cat__contact_telephone', 'cat__contact_unknown', 'cat__month_apr', 'cat__month_aug', 'cat__month_dec', 'cat__month_feb', 'cat__month_jan', 'cat__month_jul', 'cat__month_jun', 'cat__month_mar', 'cat__month_may', 'cat__month_nov', 'cat__month_oct', 'cat__month_sep', 'cat__poutcome_failure', 'cat__poutcome_other', 'cat__poutcome_success', 'cat__poutcome_unknown']\nSaved PDP plots: 51\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Build Global Explanation Text\nshap_text = f\"Top SHAP features: {shap_result['feature_names'][:10]}\"\nperm_text = f\"Top permutation features: {perm_result['feature_names'][:10]}\"\npdp_text = f\"PDP plots saved: {len(pdp_paths)}\"\nglobal_explanation = (\n   \"MODEL EXPLAINABILITY SUMMARY\\n\\n\"\n   \"Key SHAP drivers:\\n\"\n   f\"{shap_text}\\n\\n\"\n   \"Important features (permutation importance):\\n\"\n   f\"{perm_text}\\n\\n\"\n   \"PDP summary:\\n\"\n   f\"{pdp_text}\\n\"\n)\n# Save this combined text block for Narrative Agent\nartifacts[\"global_explanation_text\"] = global_explanation\nprint(\"Global explanation summary created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:00:49.254670Z","iopub.execute_input":"2025-11-30T15:00:49.255042Z","iopub.status.idle":"2025-11-30T15:00:49.262502Z","shell.execute_reply.started":"2025-11-30T15:00:49.255015Z","shell.execute_reply":"2025-11-30T15:00:49.261361Z"}},"outputs":[{"name":"stdout","text":"Global explanation summary created.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Generate Business Narrative with Gemini\n**Purpose**: Use Gemini to create a stakeholder-friendly narrative explaining the model.","metadata":{}},{"cell_type":"code","source":"NARRATIVE_SYSTEM_PROMPT = \"\"\"\nYou are an expert data scientist explaining a binary classification model\nto business stakeholders. Summarize:\n- What the model predicts\n- The most important drivers from permutation importance and PDP\n- Key patterns (e.g., thresholds, saturation)\n- 3 concise, actionable recommendations\nKeep it under 200 words. Avoid equations and low-level technical jargon.\n\"\"\"\ndef generate_narrative_with_gemini(\n   metrics: Dict[str, float],\n   global_explanation_text: str,\n   target_description: str = \"whether a customer subscribes to a term deposit\",\n) -> str:\n   if genai_client is None:\n       logger.warning(\"No Gemini client; using fallback narrative.\")\n       return (\n           f\"This model predicts {target_description} using campaign, customer, and contact features. \"\n           f\"On the held-out test data it reaches accuracy of {metrics.get('accuracy', 0):.3f} and ROC-AUC of \"\n           f\"{metrics.get('roc_auc', 0):.3f}. The most important drivers include call duration and certain \"\n           \"campaign attributes, which influence the probability of subscription. Longer and more targeted \"\n           \"conversations tend to increase conversion, while repeated contacts with poor timing reduce it. \"\n           \"Recommended next steps: monitor these top features, refine contact strategies for high-potential \"\n           \"segments, and run targeted experiments to improve uplift.\"\n       )\n   user_prompt = f\"\"\"\nMODEL METRICS:\n{json.dumps(metrics, indent=2)}\nGLOBAL EXPLANATIONS:\n{global_explanation_text}\nTARGET:\n{target_description}\n\"\"\"\n   try:\n       response = genai_client.models.generate_content(\n           model=GEMINI_MODEL,\n           contents=user_prompt,\n           config=genai_types.GenerateContentConfig(\n               temperature=1.0,\n               max_output_tokens=400,\n               system_instruction=NARRATIVE_SYSTEM_PROMPT,\n           ),\n       )\n       text = response.text.strip()\n       logger.info(\"Narrative generated with Gemini, length=%d chars.\", len(text))\n       return text\n   except Exception as e:\n       logger.error(\"Error calling Gemini for narrative: %s\", e)\n       return (\n           f\"This model predicts {target_description}. It achieves accuracy {metrics.get('accuracy', 0):.3f} \"\n           f\"and ROC-AUC {metrics.get('roc_auc', 0):.3f}. Features related to campaign interactions and \"\n           \"call duration appear most important. Longer, well-timed calls tend to increase subscription odds, \"\n           \"while repeated unsuccessful contacts may hurt performance. Recommended actions: monitor these \"\n           \"features, adjust call strategies, and test targeted outreach to high-probability groups.\"\n       )\nmetrics = artifacts[\"metrics\"]\nglobal_explanation_text = artifacts[\"global_explanation_text\"]\nnarrative_text = generate_narrative_with_gemini(\n   metrics=metrics,\n   global_explanation_text=global_explanation_text,\n)\nartifacts[\"narrative_text\"] = narrative_text\nprint(narrative_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:00:52.580521Z","iopub.execute_input":"2025-11-30T15:00:52.581647Z","iopub.status.idle":"2025-11-30T15:00:55.085919Z","shell.execute_reply.started":"2025-11-30T15:00:52.581608Z","shell.execute_reply":"2025-11-30T15:00:55.084851Z"}},"outputs":[{"name":"stdout","text":"This model predicts whether a customer will subscribe to a term deposit. It's quite accurate overall (89.5% accuracy, AUC 0.91) but less precise at identifying *who will subscribe* (F1 score 0.46).\n\nThe most important factors are the customer's age, account balance, the day of the month they were last contacted, the duration of the last call, and the number of contacts during the campaign. Also influential are attributes of their job.\n\nHere are some key patterns:\n*   Older customers are more likely to subscribe\n*   Customers with higher balances are more likely to subscribe\n\nRecommendations:\n\n1.  **Target older customers and those with higher balances.** Focus marketing efforts on these segments as they show a higher propensity to subscribe.\n2.  **Increase call duration.** Longer call durations have a positive impact on subscription rates.\n3.  **Optimize contact timing.** Focus on making calls on the days of the month when subscription rates are highest.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## LLM-as-Judge Evaluation\n**Purpose**: Use Gemini to evaluate the quality of the generated narrative.","metadata":{}},{"cell_type":"code","source":"JUDGE_SYSTEM_RUBRIC = \"\"\"\nYou are an expert ML reviewer evaluating an explanation of a supervised ML model.\nYou will receive:\n- DATASET SUMMARY\n- MODEL SUMMARY\n- GLOBAL EXPLANATIONS\n- NARRATIVE\nScore the narrative in [0,1] for:\n- technical accuracy\n- coverage of key drivers\n- clarity for stakeholders\n- actionability \nReturn ONLY a JSON object:\n{\n \"score_overall\": <float>,\n \"score_technical\": <float>,\n \"score_coverage\": <float>,\n \"score_clarity\": <float>,\n \"score_actionable\": <float>,\n \"verdict\": \"pass\" or \"needs_improvement\",\n \"comment\": \"short summary\"\n}\n\"\"\"\ndef judge_explanation_with_gemini(\n   dataset_summary: str,\n   model_summary: str,\n   global_explanations_text: str,\n   narrative_text: str,\n) -> Dict[str, Any]:\n   if genai_client is None:\n       logger.warning(\"No Gemini client; using fallback judge scores.\")\n       return {\n           \"score_overall\": 0.8,\n           \"score_technical\": 0.8,\n           \"score_coverage\": 0.8,\n           \"score_clarity\": 0.8,\n           \"score_actionable\": 0.7,\n           \"verdict\": \"pass\",\n           \"comment\": \"Fallback judge: narrative appears reasonable but Gemini was unavailable.\",\n       }\n   prompt = f\"\"\"\nDATASET SUMMARY:\n{dataset_summary}\nMODEL SUMMARY:\n{model_summary}\nGLOBAL EXPLANATIONS:\n{global_explanations_text}\nNARRATIVE:\n{narrative_text}\n\"\"\"\n   try:\n       response = genai_client.models.generate_content(\n           model=GEMINI_MODEL,\n           contents=prompt,\n           config=genai_types.GenerateContentConfig(\n               temperature=0.2,\n               max_output_tokens=512,\n               system_instruction=JUDGE_SYSTEM_RUBRIC,\n           ),\n       )\n       raw = response.text.strip()\n       try:\n           result = json.loads(raw)\n       except json.JSONDecodeError:\n           start = raw.find(\"{\")\n           end = raw.rfind(\"}\")\n           result = json.loads(raw[start : end + 1])\n       logger.info(\"Judge result: %s\", result)\n       return result\n   except Exception as e:\n       logger.error(\"Error calling Gemini judge: %s\", e)\n       return {\n           \"score_overall\": 0.6,\n           \"score_technical\": 0.6,\n           \"score_coverage\": 0.6,\n           \"score_clarity\": 0.6,\n           \"score_actionable\": 0.5,\n           \"verdict\": \"needs_improvement\",\n           \"comment\": \"LLM judge failed; rely on metrics and plots instead.\",\n       }\ndataset_summary = (\n   \"Bank Marketing dataset: binary classification predicting if a customer subscribes \"\n   \"to a term deposit based on demographics, contact history, and campaign features.\"\n)\nmodel_summary = (\n   \"LightGBM classifier with numeric scaling and one-hot encoding for categoricals. \"\n   f\"Test metrics: accuracy={metrics['accuracy']:.3f}, F1={metrics['f1']:.3f}, \"\n   f\"ROC-AUC={metrics['roc_auc']:.3f}.\"\n)\njudge_result = judge_explanation_with_gemini(\n   dataset_summary=dataset_summary,\n   model_summary=model_summary,\n   global_explanations_text=global_explanation_text,\n   narrative_text=narrative_text,\n)\nartifacts[\"judge_result\"] = judge_result\nprint(json.dumps(judge_result, indent=2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:01:09.838812Z","iopub.execute_input":"2025-11-30T15:01:09.839160Z","iopub.status.idle":"2025-11-30T15:01:11.005619Z","shell.execute_reply.started":"2025-11-30T15:01:09.839135Z","shell.execute_reply":"2025-11-30T15:01:11.004476Z"}},"outputs":[{"name":"stdout","text":"{\n  \"score_overall\": 0.85,\n  \"score_technical\": 0.9,\n  \"score_coverage\": 0.8,\n  \"score_clarity\": 0.9,\n  \"score_actionable\": 0.8,\n  \"verdict\": \"pass\",\n  \"comment\": \"Good explanation of the model and its predictions. It covers the key drivers and provides actionable recommendations. Could benefit from mentioning the limitations of relying solely on global explanations and the importance of considering individual predictions.\"\n}\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## Generate Reports\n**Purpose**: Save results as JSON and PDF reports for stakeholders.","metadata":{}},{"cell_type":"code","source":"def save_json_report(\n   artifacts: Dict[str, Any],\n   path: str = \"mlinsightx_report.json\",\n) -> str:\n   data = {\n       \"metrics\": artifacts.get(\"metrics\", {}),\n       \"global_explanation_text\": artifacts.get(\"global_explanation_text\", \"\"),\n       \"narrative_text\": artifacts.get(\"narrative_text\", \"\"),\n       \"judge_result\": artifacts.get(\"judge_result\", {}),\n       \"pdp_features\": artifacts.get(\"pdp_features\", []),\n       \"pdp_paths\": artifacts.get(\"pdp_paths\", []),\n   }\n   with open(path, \"w\") as f:\n       json.dump(data, f, indent=2)\n   logger.info(\"JSON report saved at %s\", path)\n   return path\n    \ndef save_pdf_report_simple(\n   metrics: Dict[str, float],\n   narrative_text: str,\n   judge_result: Dict[str, Any],\n   path: str = \"mlinsightx_report.pdf\",\n) -> str:\n\n   fig, ax = plt.subplots(figsize=(8.5, 11))\n   ax.axis(\"off\")\n   lines = []\n   lines.append(\"MLInsightX â€“ Model Explainer Summary\")\n   lines.append(\"\")\n   lines.append(f\"Accuracy: {metrics.get('accuracy', 0):.3f}\")\n   lines.append(f\"F1 Score: {metrics.get('f1', 0):.3f}\")\n   lines.append(f\"ROC-AUC: {metrics.get('roc_auc', 0):.3f}\")\n   lines.append(\"\")\n   lines.append(\"Narrative:\")\n   for line in narrative_text.split(\"\\n\"):\n       lines.append(line)\n   lines.append(\"\")\n   lines.append(\"LLM-as-Judge Summary:\")\n   lines.append(json.dumps(judge_result, indent=2))\n   y = 0.95\n   for line in lines:\n       ax.text(\n           0.05,\n           y,\n           line[:120],\n           fontsize=8,\n           va=\"top\",\n           wrap=True,\n       )\n       y -= 0.03\n       if y < 0.05:\n           break\n   fig.savefig(path, bbox_inches=\"tight\")\n   plt.close(fig)\n   logger.info(\"PDF report saved at %s\", path)\n   return path\njson_path = save_json_report(artifacts)\npdf_path = save_pdf_report_simple(\n   metrics=artifacts[\"metrics\"],\n   narrative_text=artifacts[\"narrative_text\"],\n   judge_result=artifacts[\"judge_result\"],\n)\nartifacts[\"json_report_path\"] = json_path\nartifacts[\"pdf_report_path\"] = pdf_path\nprint(\"JSON report:\", json_path)\nprint(\"PDF report:\", pdf_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:07:14.756163Z","iopub.execute_input":"2025-11-30T15:07:14.757591Z","iopub.status.idle":"2025-11-30T15:07:15.991647Z","shell.execute_reply.started":"2025-11-30T15:07:14.757531Z","shell.execute_reply":"2025-11-30T15:07:15.990687Z"}},"outputs":[{"name":"stdout","text":"JSON report: mlinsightx_report.json\nPDF report: mlinsightx_report.pdf\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## Access Reports\n**Purpose**: Create download links and preview the generated reports.","metadata":{}},{"cell_type":"code","source":"from IPython.display import FileLink, display\nimport json\nprint(\"=\" * 60)\nprint(\"REPORTS GENERATED\")\nprint(\"=\" * 60)\n# JSON Report\nprint(\"\\nðŸ“„ JSON Report:\")\nprint(f\"Location: {artifacts['json_report_path']}\")\ndisplay(FileLink(artifacts['json_report_path']))\n# Preview JSON content\nwith open(artifacts['json_report_path'], 'r') as f:\n   report_data = json.load(f)\n   print(\"\\nJSON Preview:\")\n   print(json.dumps(report_data, indent=2)[:500] + \"...\")\n# PDF Report  \nprint(\"\\nðŸ“‹ PDF Report:\")\nprint(f\"Location: {artifacts['pdf_report_path']}\")\ndisplay(FileLink(artifacts['pdf_report_path']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:10:44.424128Z","iopub.execute_input":"2025-11-30T15:10:44.424550Z","iopub.status.idle":"2025-11-30T15:10:44.443675Z","shell.execute_reply.started":"2025-11-30T15:10:44.424514Z","shell.execute_reply":"2025-11-30T15:10:44.442270Z"}},"outputs":[{"name":"stdout","text":"============================================================\nREPORTS GENERATED\n============================================================\n\nðŸ“„ JSON Report:\nLocation: mlinsightx_report.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/mlinsightx_report.json","text/html":"<a href='mlinsightx_report.json' target='_blank'>mlinsightx_report.json</a><br>"},"metadata":{}},{"name":"stdout","text":"\nJSON Preview:\n{\n  \"metrics\": {\n    \"accuracy\": 0.8950276243093923,\n    \"f1\": 0.46327683615819215,\n    \"roc_auc\": 0.9093560933448573\n  },\n  \"global_explanation_text\": \"MODEL EXPLAINABILITY SUMMARY\\n\\nKey SHAP drivers:\\nTop SHAP features: ['num__age', 'num__balance', 'num__day', 'num__duration', 'num__campaign', 'num__pdays', 'num__previous', 'cat__job_admin.', 'cat__job_blue-collar', 'cat__job_entrepreneur']\\n\\nImportant features (permutation importance):\\nTop permutation features: ['num__age', 'num__balance',...\n\nðŸ“‹ PDF Report:\nLocation: mlinsightx_report.pdf\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/mlinsightx_report.pdf","text/html":"<a href='mlinsightx_report.pdf' target='_blank'>mlinsightx_report.pdf</a><br>"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"## Define ADK Callbacks\n**Purpose**: Create logging callbacks for agent and model interactions.","metadata":{}},{"cell_type":"code","source":"def before_agent_callback(**kwargs):\n   callback_context = kwargs.get('callback_context')\n   logger.info(\n       \"â–¶ BEFORE_AGENT | agent=%s | invocation_id=%s\",\n       getattr(callback_context, \"agent_name\", \"unknown\"),\n       getattr(callback_context, \"invocation_id\", \"n/a\"),\n   )\n   return None\ndef after_agent_callback(**kwargs):\n   callback_context = kwargs.get('callback_context')\n   logger.info(\n       \"â—€ AFTER_AGENT | agent=%s | invocation_id=%s\",\n       getattr(callback_context, \"agent_name\", \"unknown\"),\n       getattr(callback_context, \"invocation_id\", \"n/a\"),\n   )\n   return None\ndef before_model_callback(**kwargs):\n   callback_context = kwargs.get('callback_context')\n   llm_request = kwargs.get('llm_request')\n   logger.info(\n       \"ðŸ’¬ BEFORE_MODEL | agent=%s | invocation_id=%s\",\n       getattr(callback_context, \"agent_name\", \"unknown\"),\n       getattr(callback_context, \"invocation_id\", \"n/a\"),\n   )\n   return None\ndef after_model_callback(**kwargs):\n   callback_context = kwargs.get('callback_context')\n   llm_response = kwargs.get('llm_response')\n   text_preview = \"\"\n   try:\n       if llm_response and hasattr(llm_response, 'content'):\n           text_preview = llm_response.content.parts[0].text[:200]\n   except Exception:\n       pass\n   logger.info(\n       \"ðŸ’¬ AFTER_MODEL | agent=%s | invocation_id=%s | preview=%s\",\n       getattr(callback_context, \"agent_name\", \"unknown\"),\n       getattr(callback_context, \"invocation_id\", \"n/a\"),\n       text_preview.replace(\"\\n\", \" \"),\n   )\n   return None\nprint(\"ADK callbacks defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:01:31.695210Z","iopub.execute_input":"2025-11-30T15:01:31.696130Z","iopub.status.idle":"2025-11-30T15:01:31.707221Z","shell.execute_reply.started":"2025-11-30T15:01:31.696097Z","shell.execute_reply":"2025-11-30T15:01:31.705833Z"}},"outputs":[{"name":"stdout","text":"ADK callbacks defined.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## Define Agent Tools\n**Purpose**: Create tool functions that agents can use to access artifacts.\n","metadata":{}},{"cell_type":"code","source":"#cell11\ndef trainer_summary_tool() -> dict:\n   return {\n       \"metrics\": artifacts.get(\"metrics\", {}),\n       \"target\": \"Predict term deposit subscription (y) in the Bank Marketing dataset.\",\n       \"n_train\": len(artifacts.get(\"X_train\", [])),\n       \"n_test\": len(artifacts.get(\"X_test\", [])),\n   }\ndef explainer_summary_tool() -> dict:\n   return {\n       \"global_explanation_text\": artifacts.get(\"global_explanation_text\", \"\"),\n       \"pdp_features\": artifacts.get(\"pdp_features\", []),\n       \"pdp_paths\": artifacts.get(\"pdp_paths\", []),\n   }\ndef narrative_summary_tool() -> dict:\n   return {\n       \"narrative_text\": artifacts.get(\"narrative_text\", \"\"),\n   }\ndef judge_summary_tool() -> dict:\n   return artifacts.get(\"judge_result\", {})\ndef report_paths_tool() -> dict:\n   return {\n       \"json_report_path\": artifacts.get(\"json_report_path\", None),\n       \"pdf_report_path\": artifacts.get(\"pdf_report_path\", None),\n   }\nprint(\"Summary tools for Trainer/Explainer/Narrative/Judge/Reporter defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:01:36.854578Z","iopub.execute_input":"2025-11-30T15:01:36.854926Z","iopub.status.idle":"2025-11-30T15:01:36.863141Z","shell.execute_reply.started":"2025-11-30T15:01:36.854903Z","shell.execute_reply":"2025-11-30T15:01:36.862121Z"}},"outputs":[{"name":"stdout","text":"Summary tools for Trainer/Explainer/Narrative/Judge/Reporter defined.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## Create Sub-Agents\n**Purpose**: Define sub-agents for each component of the explainability pipeline.","metadata":{}},{"cell_type":"code","source":"trainer_agent = LlmAgent(\n   name=\"trainer_agent\",\n   model=GEMINI_MODEL if GOOGLE_API_KEY else GEMINI_MODEL,\n   description=\"Trainer Agent: summarizes the trained ML model and metrics.\",\n   instruction=(\n       \"You are the Trainer Agent. Use the trainer_summary_tool to inspect model performance \"\n       \"and dataset sizes. Provide a short summary (3â€“5 sentences) of how well the model is doing.\"\n   ),\n   tools=[trainer_summary_tool],\n   before_agent_callback=before_agent_callback,\n   after_agent_callback=after_agent_callback,\n   before_model_callback=before_model_callback,\n   after_model_callback=after_model_callback,\n)\nexplainer_agent = LlmAgent(\n   name=\"explainer_agent\",\n   model=GEMINI_MODEL if GOOGLE_API_KEY else GEMINI_MODEL,\n   description=\"Explainer Agent: summarizes SHAP / permutation / PDP insights.\",\n   instruction=(\n       \"You are the Explainer Agent. Use explainer_summary_tool to read the global explanation text \"\n       \"and PDP features. Summarize the key drivers and any patterns (e.g., thresholds) in 3â€“5 sentences.\"\n   ),\n   tools=[explainer_summary_tool],\n   before_agent_callback=before_agent_callback,\n   after_agent_callback=after_agent_callback,\n   before_model_callback=before_model_callback,\n   after_model_callback=after_model_callback,\n)\nnarrative_agent = LlmAgent(\n   name=\"narrative_agent\",\n   model=GEMINI_MODEL if GOOGLE_API_KEY else GEMINI_MODEL,\n   description=\"Narrative Agent: refines the explanation into a stakeholder-facing story.\",\n   instruction=(\n       \"You are the Narrative Agent. Use narrative_summary_tool to read the existing narrative text. \"\n       \"Optionally refine or tighten the narrative for a business stakeholder, keeping it under 200 words.\"\n   ),\n   tools=[narrative_summary_tool],\n   before_agent_callback=before_agent_callback,\n   after_agent_callback=after_agent_callback,\n   before_model_callback=before_model_callback,\n   after_model_callback=after_model_callback,\n)\njudge_agent = LlmAgent(\n   name=\"judge_agent\",\n   model=GEMINI_MODEL if GOOGLE_API_KEY else GEMINI_MODEL,\n   description=\"Judge Agent: summarizes the quality evaluation of the narrative.\",\n   instruction=(\n       \"You are the Judge Agent. Use judge_summary_tool to see numeric scores and the verdict. \"\n       \"Give a concise summary (2â€“3 sentences) on whether the explanation is strong and what could be improved.\"\n   ),\n   tools=[judge_summary_tool],\n   before_agent_callback=before_agent_callback,\n   after_agent_callback=after_agent_callback,\n   before_model_callback=before_model_callback,\n   after_model_callback=after_model_callback,\n)\nreporter_agent = LlmAgent(\n   name=\"reporter_agent\",\n   model=GEMINI_MODEL if GOOGLE_API_KEY else GEMINI_MODEL,\n   description=\"Reporter Agent: tells the user where to find JSON/PDF artifacts.\",\n   instruction=(\n       \"You are the Reporter Agent. Use report_paths_tool to get the JSON and PDF report paths. \"\n       \"Summarize what artifacts exist and how they could be used.\"\n   ),\n   tools=[report_paths_tool],\n   before_agent_callback=before_agent_callback,\n   after_agent_callback=after_agent_callback,\n   before_model_callback=before_model_callback,\n   after_model_callback=after_model_callback,\n)\nprint(\"Trainer, Explainer, Narrative, Judge, Reporter agents defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:01:40.214859Z","iopub.execute_input":"2025-11-30T15:01:40.215357Z","iopub.status.idle":"2025-11-30T15:01:40.227392Z","shell.execute_reply.started":"2025-11-30T15:01:40.215327Z","shell.execute_reply":"2025-11-30T15:01:40.226294Z"}},"outputs":[{"name":"stdout","text":"Trainer, Explainer, Narrative, Judge, Reporter agents defined.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## Create Orchestrator & Runner\n**Purpose**: Build the orchestrator agent that coordinates all sub-agents and initialize the runner.","metadata":{}},{"cell_type":"code","source":"callbacks = {\n   \"before_agent_callback\": before_agent_callback,\n   \"after_agent_callback\": after_agent_callback,\n   \"before_model_callback\": before_model_callback,\n   \"after_model_callback\": after_model_callback,\n}\ntrainer_tool = AgentTool(trainer_agent)\nexplainer_tool = AgentTool(explainer_agent)\nnarrative_tool = AgentTool(narrative_agent)\njudge_tool = AgentTool(judge_agent)\nreporter_tool = AgentTool(reporter_agent)\n# Orchestrator instruction\norchestrator_instruction = \"\"\"\nYou are the Orchestrator Agent for the Insight system.\nFollow this workflow:\n1. Call trainer_agent to summarize model performance.\n2. Call explainer_agent to summarize SHAP, permutation, PDP.\n3. Call narrative_agent to create a business-ready explanation.\n4. Call judge_agent to evaluate explanation quality.\n5. Call reporter_agent to notify about saved JSON/PDF outputs.\nReturn a structured, multi-paragraph overview for stakeholders.\n\"\"\"\n# Orchestrator Agent \norchestrator_agent = LlmAgent(\n   name=\"orchestrator_agent\",\n   model=GEMINI_MODEL,\n   instruction=orchestrator_instruction,\n   tools=[\n       trainer_tool,\n       explainer_tool,\n       narrative_tool,\n       judge_tool,\n       reporter_tool\n   ],\n   **callbacks\n)\nprint(\"Orchestrator agent defined.\")\n# Runner\nrunner = InMemoryRunner(agent=orchestrator_agent)\nprint(\"Runner initialized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:01:55.675581Z","iopub.execute_input":"2025-11-30T15:01:55.675930Z","iopub.status.idle":"2025-11-30T15:01:55.685108Z","shell.execute_reply.started":"2025-11-30T15:01:55.675904Z","shell.execute_reply":"2025-11-30T15:01:55.684093Z"}},"outputs":[{"name":"stdout","text":"Orchestrator agent defined.\nRunner initialized.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Runner Run\n_ = await runner.run_debug(\n   \"Give me full overview\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:02:00.728112Z","iopub.execute_input":"2025-11-30T15:02:00.728533Z","iopub.status.idle":"2025-11-30T15:02:08.473870Z","shell.execute_reply.started":"2025-11-30T15:02:00.728507Z","shell.execute_reply":"2025-11-30T15:02:08.472734Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Give me full overview\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call', 'function_call', 'function_call', 'function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"orchestrator_agent > Here's an overview of the model's performance and key insights:\n\n**Model Performance:** The model demonstrates strong overall prediction performance with an accuracy of 89.5% on the test set and a high ROC AUC score of 0.91, indicating its ability to distinguish between positive and negative classes. However, the F1 score is 0.46, suggesting that the model has relatively low precision and recall. It was trained on 3,616 samples and tested on 905 samples, predicting term deposit subscriptions.\n\n**Key Drivers:** Model predictions are significantly influenced by numerical features such as age, balance, day, duration, campaign, pdays, and previous. Categorical features related to job type (admin, blue-collar, and entrepreneur) also play a crucial role.\n\n**Explanation Quality:** The explanation is well-structured, covering key drivers and providing actionable recommendations. To further enhance its quality, it would benefit from addressing the limitations of relying solely on global explanations and highlighting the importance of considering individual predictions.\n\n**Artifacts:** Detailed reports are available in JSON format at `insightops_report.json` and in PDF format at `insightops_report.pdf`. These files can be used for in-depth analysis and sharing with stakeholders.\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## Display Results\n**Purpose**: Print all key outputs from the multi-agents ML system including metrics, explanations, narratives, and report paths.","metadata":{}},{"cell_type":"code","source":"print(\"=== MODEL METRICS ===\")\nprint(json.dumps(artifacts[\"metrics\"], indent=2))\nprint(\"\\n=== GLOBAL EXPLANATION (Permutation + PDP) ===\")\nprint(artifacts[\"global_explanation_text\"])\nprint(\"\\n=== NARRATIVE TEXT ===\")\nprint(artifacts[\"narrative_text\"])\nprint(\"\\n=== LLM-as-Judge RESULT ===\")\nprint(json.dumps(artifacts[\"judge_result\"], indent=2))\nprint(\"\\nJSON report path:\", artifacts[\"json_report_path\"])\nprint(\"PDF report path:\", artifacts[\"pdf_report_path\"])\nprint(\"PDP plots:\", artifacts[\"pdp_paths\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:20:04.542277Z","iopub.execute_input":"2025-11-30T15:20:04.543621Z","iopub.status.idle":"2025-11-30T15:20:04.551158Z","shell.execute_reply.started":"2025-11-30T15:20:04.543580Z","shell.execute_reply":"2025-11-30T15:20:04.549911Z"}},"outputs":[{"name":"stdout","text":"=== MODEL METRICS ===\n{\n  \"accuracy\": 0.8950276243093923,\n  \"f1\": 0.46327683615819215,\n  \"roc_auc\": 0.9093560933448573\n}\n\n=== GLOBAL EXPLANATION (Permutation + PDP) ===\nMODEL EXPLAINABILITY SUMMARY\n\nKey SHAP drivers:\nTop SHAP features: ['num__age', 'num__balance', 'num__day', 'num__duration', 'num__campaign', 'num__pdays', 'num__previous', 'cat__job_admin.', 'cat__job_blue-collar', 'cat__job_entrepreneur']\n\nImportant features (permutation importance):\nTop permutation features: ['num__age', 'num__balance', 'num__day', 'num__duration', 'num__campaign', 'num__pdays', 'num__previous', 'cat__job_admin.', 'cat__job_blue-collar', 'cat__job_entrepreneur']\n\nPDP summary:\nPDP plots saved: 51\n\n\n=== NARRATIVE TEXT ===\nThis model predicts whether a customer will subscribe to a term deposit. It's quite accurate overall (89.5% accuracy, AUC 0.91) but less precise at identifying *who will subscribe* (F1 score 0.46).\n\nThe most important factors are the customer's age, account balance, the day of the month they were last contacted, the duration of the last call, and the number of contacts during the campaign. Also influential are attributes of their job.\n\nHere are some key patterns:\n*   Older customers are more likely to subscribe\n*   Customers with higher balances are more likely to subscribe\n\nRecommendations:\n\n1.  **Target older customers and those with higher balances.** Focus marketing efforts on these segments as they show a higher propensity to subscribe.\n2.  **Increase call duration.** Longer call durations have a positive impact on subscription rates.\n3.  **Optimize contact timing.** Focus on making calls on the days of the month when subscription rates are highest.\n\n=== LLM-as-Judge RESULT ===\n{\n  \"score_overall\": 0.85,\n  \"score_technical\": 0.9,\n  \"score_coverage\": 0.8,\n  \"score_clarity\": 0.9,\n  \"score_actionable\": 0.8,\n  \"verdict\": \"pass\",\n  \"comment\": \"Good explanation of the model and its predictions. It covers the key drivers and provides actionable recommendations. Could benefit from mentioning the limitations of relying solely on global explanations and the importance of considering individual predictions.\"\n}\n\nJSON report path: mlinsightx_report.json\nPDF report path: mlinsightx_report.pdf\nPDP plots: ['pdp_plots/pdp_num__age.png', 'pdp_plots/pdp_num__balance.png', 'pdp_plots/pdp_num__day.png', 'pdp_plots/pdp_num__duration.png', 'pdp_plots/pdp_num__campaign.png', 'pdp_plots/pdp_num__pdays.png', 'pdp_plots/pdp_num__previous.png', 'pdp_plots/pdp_cat__job_admin..png', 'pdp_plots/pdp_cat__job_blue-collar.png', 'pdp_plots/pdp_cat__job_entrepreneur.png', 'pdp_plots/pdp_cat__job_housemaid.png', 'pdp_plots/pdp_cat__job_management.png', 'pdp_plots/pdp_cat__job_retired.png', 'pdp_plots/pdp_cat__job_self-employed.png', 'pdp_plots/pdp_cat__job_services.png', 'pdp_plots/pdp_cat__job_student.png', 'pdp_plots/pdp_cat__job_technician.png', 'pdp_plots/pdp_cat__job_unemployed.png', 'pdp_plots/pdp_cat__job_unknown.png', 'pdp_plots/pdp_cat__marital_divorced.png', 'pdp_plots/pdp_cat__marital_married.png', 'pdp_plots/pdp_cat__marital_single.png', 'pdp_plots/pdp_cat__education_primary.png', 'pdp_plots/pdp_cat__education_secondary.png', 'pdp_plots/pdp_cat__education_tertiary.png', 'pdp_plots/pdp_cat__education_unknown.png', 'pdp_plots/pdp_cat__default_no.png', 'pdp_plots/pdp_cat__default_yes.png', 'pdp_plots/pdp_cat__housing_no.png', 'pdp_plots/pdp_cat__housing_yes.png', 'pdp_plots/pdp_cat__loan_no.png', 'pdp_plots/pdp_cat__loan_yes.png', 'pdp_plots/pdp_cat__contact_cellular.png', 'pdp_plots/pdp_cat__contact_telephone.png', 'pdp_plots/pdp_cat__contact_unknown.png', 'pdp_plots/pdp_cat__month_apr.png', 'pdp_plots/pdp_cat__month_aug.png', 'pdp_plots/pdp_cat__month_dec.png', 'pdp_plots/pdp_cat__month_feb.png', 'pdp_plots/pdp_cat__month_jan.png', 'pdp_plots/pdp_cat__month_jul.png', 'pdp_plots/pdp_cat__month_jun.png', 'pdp_plots/pdp_cat__month_mar.png', 'pdp_plots/pdp_cat__month_may.png', 'pdp_plots/pdp_cat__month_nov.png', 'pdp_plots/pdp_cat__month_oct.png', 'pdp_plots/pdp_cat__month_sep.png', 'pdp_plots/pdp_cat__poutcome_failure.png', 'pdp_plots/pdp_cat__poutcome_other.png', 'pdp_plots/pdp_cat__poutcome_success.png', 'pdp_plots/pdp_cat__poutcome_unknown.png']\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"## A2A Protocol Wrapper \n**Purpose**: Optional A2A protocol wrapper around the Orchestrator Agent for API endpoint.","metadata":{}},{"cell_type":"code","source":"try:\n   a2a_app = to_a2a(orchestrator_agent, port=8001)\n   logger.info(\n       \"A2A app created for orchestrator_agent on port 8001. \"\n   )\nexcept Exception as e:\n   logger.warning(\"Could not create A2A app in this environment: %s\", e)\nprint(\"A2A wrapper code defined.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}